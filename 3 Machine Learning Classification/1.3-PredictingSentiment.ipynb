{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing Turi Create functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Use SFrames to do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183531 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0                                Planetwise Flannel Wipes   \n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \n",
       "0       These flannel wipes are OK, but in my opinion ...       3  \n",
       "1       it came early and was not disappointed. i love...       5  \n",
       "2       Very soft and comfortable and warmer than it l...       5  \n",
       "3       This is a product well worth the purchase.  I ...       5  \n",
       "4       All of my kids have cried non-stop when I trie...       5  \n",
       "...                                                   ...     ...  \n",
       "183526  Such a great idea! very handy to have and look...       5  \n",
       "183527  This product rocks!  It is a great blend of fu...       5  \n",
       "183528  This item looks great and cool for my kids.......       5  \n",
       "183529  I am extremely happy with this product. I have...       5  \n",
       "183530  I love this product very mush . I have bought ...       5  \n",
       "\n",
       "[183531 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these flannel wipes are ok but in my opinion not worth keeping i also ordered someimse vimse cloth wipes ocean blue countwhich are larger had a nicer softer texture and just seemed higher quality i use cloth wipes for hands and faces and have been usingthirsties pack fab wipes boyfor about months now and need to replace them because they are starting to get rough and have had stink issues for a while that stripping no longer handles \n"
     ]
    }
   ],
   "source": [
    "# Function that cleans text by removing '\\x0c' and '\\n' characters\n",
    "# as well as all non-alpha characters and finally converts everything\n",
    "# to lower case\n",
    "\n",
    "def clean_text(text):\n",
    "    #translator = text.maketrans('', '', string.punctuation)\n",
    "    #clean_text = text.translate(translator)\n",
    "    # remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # remove all non-alpha characters and converts to lower case\n",
    "    text = re.sub('[^a-zA-Z]+', ' ', text).lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "test_str = products['review'][0]\n",
    "print(clean_text(test_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**. Make sure to fill n/a values in the **review** column with empty strings (if applicable). The n/a values indicate empty reviews. For instance, Pandas's the fillna() method lets you replace all N/A's in the **review** columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>these flannel wipes are ok but in my opinion n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>very soft and comfortable and warmer than it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>this is a product well worth the purchase i ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>all of my kids have cried non stop when i trie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "      <td>such a great idea very handy to have and look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "      <td>this product rocks it is a great blend of func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "      <td>this item looks great and cool for my kids i k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "      <td>i am extremely happy with this product i have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this product very mush i have bought ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183531 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0                                Planetwise Flannel Wipes   \n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "0       These flannel wipes are OK, but in my opinion ...       3   \n",
       "1       it came early and was not disappointed. i love...       5   \n",
       "2       Very soft and comfortable and warmer than it l...       5   \n",
       "3       This is a product well worth the purchase.  I ...       5   \n",
       "4       All of my kids have cried non-stop when I trie...       5   \n",
       "...                                                   ...     ...   \n",
       "183526  Such a great idea! very handy to have and look...       5   \n",
       "183527  This product rocks!  It is a great blend of fu...       5   \n",
       "183528  This item looks great and cool for my kids.......       5   \n",
       "183529  I am extremely happy with this product. I have...       5   \n",
       "183530  I love this product very mush . I have bought ...       5   \n",
       "\n",
       "                                             review_clean  \n",
       "0       these flannel wipes are ok but in my opinion n...  \n",
       "1       it came early and was not disappointed i love ...  \n",
       "2       very soft and comfortable and warmer than it l...  \n",
       "3       this is a product well worth the purchase i ha...  \n",
       "4       all of my kids have cried non stop when i trie...  \n",
       "...                                                   ...  \n",
       "183526  such a great idea very handy to have and look ...  \n",
       "183527  this product rocks it is a great blend of func...  \n",
       "183528  this item looks great and cool for my kids i k...  \n",
       "183529  i am extremely happy with this product i have ...  \n",
       "183530  i love this product very mush i have bought ma...  \n",
       "\n",
       "[183531 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "products['review_clean'] = products['review'].apply(clean_text)\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yc1033514\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>these flannel wipes are ok but in my opinion n...</td>\n",
       "      <td>{'these': 2, 'flannel': 2, 'wipes': 4, 'are': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>{'it': 4, 'came': 2, 'early': 2, 'and': 4, 'wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>very soft and comfortable and warmer than it l...</td>\n",
       "      <td>{'very': 2, 'soft': 2, 'and': 3, 'comfortable'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>this is a product well worth the purchase i ha...</td>\n",
       "      <td>{'this': 5, 'is': 5, 'a': 3, 'product': 3, 'we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>all of my kids have cried non stop when i trie...</td>\n",
       "      <td>{'all': 3, 'of': 2, 'my': 2, 'kids': 3, 'have'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "      <td>such a great idea very handy to have and look ...</td>\n",
       "      <td>{'such': 2, 'a': 2, 'great': 3, 'idea!': 2, 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "      <td>this product rocks it is a great blend of func...</td>\n",
       "      <td>{'this': 2, 'product': 3, 'rocks!': 2, 'it': 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "      <td>this item looks great and cool for my kids i k...</td>\n",
       "      <td>{'this': 3, 'item': 2, 'looks': 2, 'great': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "      <td>i am extremely happy with this product i have ...</td>\n",
       "      <td>{'i': 10, 'am': 3, 'extremely': 2, 'happy': 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this product very mush i have bought ma...</td>\n",
       "      <td>{'i': 3, 'love': 2, 'this': 2, 'product': 2, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183531 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0                                Planetwise Flannel Wipes   \n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "0       These flannel wipes are OK, but in my opinion ...       3   \n",
       "1       it came early and was not disappointed. i love...       5   \n",
       "2       Very soft and comfortable and warmer than it l...       5   \n",
       "3       This is a product well worth the purchase.  I ...       5   \n",
       "4       All of my kids have cried non-stop when I trie...       5   \n",
       "...                                                   ...     ...   \n",
       "183526  Such a great idea! very handy to have and look...       5   \n",
       "183527  This product rocks!  It is a great blend of fu...       5   \n",
       "183528  This item looks great and cool for my kids.......       5   \n",
       "183529  I am extremely happy with this product. I have...       5   \n",
       "183530  I love this product very mush . I have bought ...       5   \n",
       "\n",
       "                                             review_clean  \\\n",
       "0       these flannel wipes are ok but in my opinion n...   \n",
       "1       it came early and was not disappointed i love ...   \n",
       "2       very soft and comfortable and warmer than it l...   \n",
       "3       this is a product well worth the purchase i ha...   \n",
       "4       all of my kids have cried non stop when i trie...   \n",
       "...                                                   ...   \n",
       "183526  such a great idea very handy to have and look ...   \n",
       "183527  this product rocks it is a great blend of func...   \n",
       "183528  this item looks great and cool for my kids i k...   \n",
       "183529  i am extremely happy with this product i have ...   \n",
       "183530  i love this product very mush i have bought ma...   \n",
       "\n",
       "                                               word_count  \n",
       "0       {'these': 2, 'flannel': 2, 'wipes': 4, 'are': ...  \n",
       "1       {'it': 4, 'came': 2, 'early': 2, 'and': 4, 'wa...  \n",
       "2       {'very': 2, 'soft': 2, 'and': 3, 'comfortable'...  \n",
       "3       {'this': 5, 'is': 5, 'a': 3, 'product': 3, 'we...  \n",
       "4       {'all': 3, 'of': 2, 'my': 2, 'kids': 3, 'have'...  \n",
       "...                                                   ...  \n",
       "183526  {'such': 2, 'a': 2, 'great': 3, 'idea!': 2, 'v...  \n",
       "183527  {'this': 2, 'product': 3, 'rocks!': 2, 'it': 3...  \n",
       "183528  {'this': 3, 'item': 2, 'looks': 2, 'great': 3,...  \n",
       "183529  {'i': 10, 'am': 3, 'extremely': 2, 'happy': 2,...  \n",
       "183530  {'i': 3, 'love': 2, 'this': 2, 'product': 2, '...  \n",
       "\n",
       "[183531 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an empty column to dataframe using assign\n",
    "products['word_count'] = ''\n",
    "\n",
    "for i in range(len(products)):\n",
    "    d = {}\n",
    "    \n",
    "    if pd.isna(products['review'][i]):\n",
    "        products[\"word_count\"][i] = d\n",
    "    else:\n",
    "        word_list = [word.strip(\",.\") for word in products['review'][i].lower().split()]\n",
    "        for word in word_list:\n",
    "            if word not in d:\n",
    "                d[word] = 1\n",
    "            d[word] += 1\n",
    "        products[\"word_count\"][i] = d\n",
    "\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166752"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yc1033514\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>{'it': 4, 'came': 2, 'early': 2, 'and': 4, 'wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>very soft and comfortable and warmer than it l...</td>\n",
       "      <td>{'very': 2, 'soft': 2, 'and': 3, 'comfortable'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>this is a product well worth the purchase i ha...</td>\n",
       "      <td>{'this': 5, 'is': 5, 'a': 3, 'product': 3, 'we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>all of my kids have cried non stop when i trie...</td>\n",
       "      <td>{'all': 3, 'of': 2, 'my': 2, 'kids': 3, 'have'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>when the binky fairy came to our house we didn...</td>\n",
       "      <td>{'when': 3, 'the': 7, 'binky': 4, 'fairy': 4, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "      <td>such a great idea very handy to have and look ...</td>\n",
       "      <td>{'such': 2, 'a': 2, 'great': 3, 'idea!': 2, 'v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "      <td>this product rocks it is a great blend of func...</td>\n",
       "      <td>{'this': 2, 'product': 3, 'rocks!': 2, 'it': 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "      <td>this item looks great and cool for my kids i k...</td>\n",
       "      <td>{'this': 3, 'item': 2, 'looks': 2, 'great': 3,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "      <td>i am extremely happy with this product i have ...</td>\n",
       "      <td>{'i': 10, 'am': 3, 'extremely': 2, 'happy': 2,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "      <td>i love this product very mush i have bought ma...</td>\n",
       "      <td>{'i': 3, 'love': 2, 'this': 2, 'product': 2, '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166752 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "5       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "1       it came early and was not disappointed. i love...       5   \n",
       "2       Very soft and comfortable and warmer than it l...       5   \n",
       "3       This is a product well worth the purchase.  I ...       5   \n",
       "4       All of my kids have cried non-stop when I trie...       5   \n",
       "5       When the Binky Fairy came to our house, we did...       5   \n",
       "...                                                   ...     ...   \n",
       "183526  Such a great idea! very handy to have and look...       5   \n",
       "183527  This product rocks!  It is a great blend of fu...       5   \n",
       "183528  This item looks great and cool for my kids.......       5   \n",
       "183529  I am extremely happy with this product. I have...       5   \n",
       "183530  I love this product very mush . I have bought ...       5   \n",
       "\n",
       "                                             review_clean  \\\n",
       "1       it came early and was not disappointed i love ...   \n",
       "2       very soft and comfortable and warmer than it l...   \n",
       "3       this is a product well worth the purchase i ha...   \n",
       "4       all of my kids have cried non stop when i trie...   \n",
       "5       when the binky fairy came to our house we didn...   \n",
       "...                                                   ...   \n",
       "183526  such a great idea very handy to have and look ...   \n",
       "183527  this product rocks it is a great blend of func...   \n",
       "183528  this item looks great and cool for my kids i k...   \n",
       "183529  i am extremely happy with this product i have ...   \n",
       "183530  i love this product very mush i have bought ma...   \n",
       "\n",
       "                                               word_count  sentiment  \n",
       "1       {'it': 4, 'came': 2, 'early': 2, 'and': 4, 'wa...          1  \n",
       "2       {'very': 2, 'soft': 2, 'and': 3, 'comfortable'...          1  \n",
       "3       {'this': 5, 'is': 5, 'a': 3, 'product': 3, 'we...          1  \n",
       "4       {'all': 3, 'of': 2, 'my': 2, 'kids': 3, 'have'...          1  \n",
       "5       {'when': 3, 'the': 7, 'binky': 4, 'fairy': 4, ...          1  \n",
       "...                                                   ...        ...  \n",
       "183526  {'such': 2, 'a': 2, 'great': 3, 'idea!': 2, 'v...          1  \n",
       "183527  {'this': 2, 'product': 3, 'rocks!': 2, 'it': 3...          1  \n",
       "183528  {'this': 3, 'item': 2, 'looks': 2, 'great': 3,...          1  \n",
       "183529  {'i': 10, 'am': 3, 'extremely': 2, 'happy': 2,...          1  \n",
       "183530  {'i': 3, 'love': 2, 'this': 2, 'product': 2, '...          1  \n",
       "\n",
       "[166752 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = products['review_clean']\n",
    "y = products['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the column **word_count** as a feature and the column **sentiment** as the target. We will use `validation_set=None` to obtain same results as everyone else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as **bag-of-word features**. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "* Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "* Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "* Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix **train_matrix**.\n",
    "* Using the same mapping between words and columns, convert the test data into a sparse matrix **test_matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(X_train)\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yc1033514\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression().fit(train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: [[ 0.0253789   0.17961501  0.12411337 ...  0.00105015  0.00102493\n",
      "  -0.00050556]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficient: {}\".format(model1.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive weights: 37540 \n",
      "Number of negative weights: 16287 \n"
     ]
    }
   ],
   "source": [
    "weights = model1.coef_\n",
    "num_positive_weights = len([x for x in weights[0] if x > 0])\n",
    "num_negative_weights = len([x for x in weights[0] if x < 0])\n",
    "\n",
    "print(\"Number of positive weights: %s \" % num_positive_weights)\n",
    "print(\"Number of negative weights: %s \" % num_negative_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data = test_matrix[10:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores** using Turi Create. For each row, the **score** (or margin) is a number in the range **[-inf, inf]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your class predictions match with the one obtained from Turi Create.\n",
    "\n",
    "### Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 1 1]\n",
      "Probability Prediction: [[3.96471438e-04 9.99603529e-01]\n",
      " [3.44356780e-05 9.99965564e-01]\n",
      " [5.72403784e-02 9.42759622e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions: {}\".format(model1.predict(sample_test_data)))\n",
    "print(\"Probability Prediction: {}\".format(model1.predict_proba(sample_test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training set: 0.9466720639275568\n",
      "Accuracy of testing set: 0.9331654223261672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict_train = model1.predict(train_matrix)\n",
    "y_predict_test = model1.predict(test_matrix)\n",
    "\n",
    "print(\"Accuracy of training set: {}\".format(accuracy_score(y_train, y_predict_train)))\n",
    "print(\"Accuracy of testing set: {}\".format(accuracy_score(y_test, y_predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subset of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(X_train)\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogisticRegression().fit(train_matrix_word_subset, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training set: 0.8676321766703398\n",
      "Accuracy of testing set: 0.8677400977481935\n"
     ]
    }
   ],
   "source": [
    "y_predict_train2 = model2.predict(train_matrix_word_subset)\n",
    "y_predict_test2 = model2.predict(test_matrix_word_subset)\n",
    "\n",
    "print(\"Accuracy of training set: {}\".format(accuracy_score(y_train, y_predict_train2)))\n",
    "print(\"Accuracy of testing set: {}\".format(accuracy_score(y_test, y_predict_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.34909935,  0.94905156,  1.1646764 ,  0.09284139,  0.48257589,\n",
       "         1.51325225,  1.73334205,  0.52827527,  0.21061647,  0.06148821,\n",
       "        -1.69813896, -0.14612021, -0.53772699, -2.06513161, -2.32227148,\n",
       "        -0.65417819, -0.31438264, -0.8778852 , -0.33132865, -2.07628285]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
